# -*- coding: utf-8 -*-
"""CSD201027AIassign2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OWzGvOct6ZGoX_55YblND2XJCsENFoL-
"""

import re
import bz2
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

# Function to preprocess the document text
def preprocess_text(text):
    # Convert to lowercase
    text = text.lower()
    # Remove special characters and digits
    text = re.sub(r'[^a-z\s]', '', text)
    return text

# Load and preprocess training data
train_data = []
train_labels = []

train_file_english = '/content/train_directory/eng_sentences.tsv.bz2'  # Specify the path to the English training data .bz2 file
train_file_french = '/content/train_directory/fra_sentences.tsv.bz2'  # Specify the path to the French training data .bz2 file
train_file_italian = '/content/train_directory/ita_sentences.tsv.bz2'  # Specify the path to the Italian training data .bz2 file

# Load English training data
with bz2.open(train_file_english, 'rt', encoding='utf-8') as file:
    for line in file:
        text = line.strip()
        preprocessed_text = preprocess_text(text)
        train_data.append(preprocessed_text)
        train_labels.append('English')  # Assign the label 'English' for English training data

# Load French training data
with bz2.open(train_file_french, 'rt', encoding='utf-8') as file:
    for line in file:
        text = line.strip()
        preprocessed_text = preprocess_text(text)
        train_data.append(preprocessed_text)
        train_labels.append('French')  # Assign the label 'French' for French training data

# Load Italian training data
with bz2.open(train_file_italian, 'rt', encoding='utf-8') as file:
    for line in file:
        text = line.strip()
        preprocessed_text = preprocess_text(text)
        train_data.append(preprocessed_text)
        train_labels.append('Italian')  # Assign the label 'Italian' for Italian training data

# Vectorize the text data
vectorizer = CountVectorizer()
features_train = vectorizer.fit_transform(train_data)

# Train the Naive Bayes model
model = MultinomialNB()
model.fit(features_train, train_labels)

# Specify the file for prediction
file_to_predict = '/content/test_directory/test.txt'  # Specify the path to the file to predict

with open(file_to_predict, 'r', encoding='utf-8') as file:
    document = file.read().strip()
    preprocessed_doc = preprocess_text(document)
    features_doc = vectorizer.transform([preprocessed_doc])
    predicted_language = model.predict(features_doc)[0]

# Check if the predicted language is English, French or Italian
is_english = predicted_language == 'English'
is_french = predicted_language == 'French'
is_italian = predicted_language == 'Italian'

print("Document:", document)
print("Predicted Language:", predicted_language)
if is_english:
    print("Language is English")
elif is_french:
    print("Language is French")
elif is_italian:
    print("Language is Italian")
else:
    print("Unable to Identify")

# Load and preprocess test data
test_data = []
test_labels = []

test_file = '/content/test_directory/test.txt'  # Specify the path to the test data .txt file

with open(test_file, 'r', encoding='utf-8') as file:
    for line in file:
        text = line.strip()
        preprocessed_text = preprocess_text(text)
        test_data.append(preprocessed_text)
        # Assume the test data is labeled with the correct languages
        test_labels.append('English')  # Assign the label 'English' for English test data

# Vectorize the test data
features_test = vectorizer.transform(test_data)

# Predict the languages of test documents
predictions = model.predict(features_test)

# Evaluate the accuracy of the predictions
accuracy = accuracy_score(test_labels, predictions)
print("Accuracy:", accuracy)

"""# New Section"""